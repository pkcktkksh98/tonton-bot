
# Tonton FAQ Bot ğŸ¤–

This project is a chatbot that answers frequently asked questions about Tonton, a Malaysian streaming platform. It uses local LLM inference, FAISS-based retrieval, and a Streamlit UI.

---

## ğŸ³ Docker Setup

You can containerize and run the Tonton FAQ Bot using Docker with the following steps:

### ğŸ“¦ 1. Build the Docker Image

Make sure you're in the root project directory (same level as the `Dockerfile`), then run:

```bash
docker build -t tonton-bot .
```

### â–¶ï¸ 2. Run the Container

```bash
docker run -p 8501:8501 tonton-bot
```

Once running, open your browser and go to:

```
http://localhost:8501
```

### ğŸ§  Note on Model Files

If you're using a large `.gguf` model file and prefer not to copy it into the Docker image, mount the model directory at runtime:

```bash
docker run -p 8501:8501 -v ${PWD}/models:/app/models tonton-bot
```

If you're on Windows (CMD or PowerShell), use:

```cmd
docker run -p 8501:8501 -v D:\01_CodingProject\04_REV\models:/app/models tonton-bot
```

### âš ï¸ Troubleshooting

- If Streamlit gives a "Runtime instance already exists!" error, make sure `app/run.py` **does not call** `stcli.main()` inside the script.
- Always access the app at `http://localhost:8501`, not `0.0.0.0`.

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ run.py
â”‚   â”œâ”€â”€ generator.py
â”‚   â”œâ”€â”€ retriever.py
â”‚   â”œâ”€â”€ interface.py
â”‚   â””â”€â”€ ingest.py
â”œâ”€â”€ data/
â”‚   â””â”€â”€ tonton_faq.txt
â”œâ”€â”€ faiss_index/
â”‚   â”œâ”€â”€ index.faiss
â”‚   â””â”€â”€ index.pkl
â””â”€â”€ models/
    â””â”€â”€ your-model.gguf
```
